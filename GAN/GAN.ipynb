{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b187889b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, Reshape, Conv2DTranspose\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb2ab482",
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainx, trainy),(testx, testy) = tf.keras.datasets.mnist.load_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71719a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02e34377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainx[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21bde9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(64, (3,3), strides=(2, 2), padding='same', input_shape=(28,28,1), activation = 'relu'),\n",
    "    Dropout(0.4),\n",
    "    Conv2D(64, (3,3), strides=(2, 2), padding='same', activation = 'relu'),\n",
    "    Dropout(0.4),\n",
    "    Flatten(),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84a10464",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e52a84ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(model,show_shapes=True,show_layer_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "581a0137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 14, 14, 64)        640       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3136)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 3137      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,705\n",
      "Trainable params: 40,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f1c407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expanding the dimensions because the CNN layer expects \n",
    "#the dimensions of the input to be 3 dimensional and the image is of 2d (28x28)\n",
    "\n",
    "X = np.expand_dims(trainx, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "becd23b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype('float32')\n",
    "X = X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44a8e14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that takes in input the dataset , noofsample and returns those number of samples from real dataset along\n",
    "# with ylabel as 1 because these small real data sample will later be used to train the GAN model\n",
    "\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "    ix = np.random.randint(0, dataset.shape[0], n_samples)\n",
    "    # retrieve selected images\n",
    "    X = dataset[ix]\n",
    "    y = np.ones((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "449da1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that takes in input the noofsamples and returns those number of arbitrarily generated samples along\n",
    "# with ylabel as 0 because these small fake data sample will later be used to train the GAN model\n",
    "\n",
    "def generate_fake_samples(n_samples):\n",
    "    X = np.random.rand(28 * 28 * n_samples)\n",
    "    X = X.reshape((n_samples, 28, 28, 1))\n",
    "    y = np.zeros((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d83cb3",
   "metadata": {},
   "source": [
    "Training the discriminator model, we aren't using the model.fit()  function because we entering the number of epochs manually and we aren't actually training the model on whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30a81c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(model, dataset, n_iter=100, n_batch=256):\n",
    "    half_batch = int(n_batch / 2)\n",
    "    # manually enumerate epochs\n",
    "    for i in range(n_iter):\n",
    "        # get randomly selected 'real' samples\n",
    "        X_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "        # update discriminator on real samples\n",
    "        _, real_acc = model.train_on_batch(X_real, y_real)\n",
    "        # generate 'fake' examples\n",
    "        X_fake, y_fake = generate_fake_samples(half_batch)\n",
    "        # update discriminator on fake samples\n",
    "        _, fake_acc = model.train_on_batch(X_fake, y_fake)\n",
    "        # summarize performance\n",
    "        print('>%d real=%.0f%% fake=%.0f%%' % (i+1, real_acc*100, fake_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2ba28af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 real=70% fake=0%\n",
      ">2 real=99% fake=5%\n",
      ">3 real=100% fake=45%\n",
      ">4 real=98% fake=95%\n",
      ">5 real=97% fake=100%\n",
      ">6 real=95% fake=100%\n",
      ">7 real=92% fake=100%\n",
      ">8 real=90% fake=100%\n",
      ">9 real=93% fake=100%\n",
      ">10 real=90% fake=100%\n",
      ">11 real=91% fake=100%\n",
      ">12 real=96% fake=100%\n",
      ">13 real=95% fake=100%\n",
      ">14 real=98% fake=100%\n",
      ">15 real=99% fake=100%\n",
      ">16 real=100% fake=100%\n",
      ">17 real=100% fake=100%\n",
      ">18 real=100% fake=100%\n",
      ">19 real=100% fake=100%\n",
      ">20 real=100% fake=100%\n",
      ">21 real=100% fake=100%\n",
      ">22 real=100% fake=100%\n",
      ">23 real=100% fake=100%\n",
      ">24 real=100% fake=100%\n",
      ">25 real=100% fake=100%\n",
      ">26 real=100% fake=100%\n",
      ">27 real=99% fake=100%\n",
      ">28 real=100% fake=100%\n",
      ">29 real=100% fake=100%\n",
      ">30 real=100% fake=100%\n",
      ">31 real=100% fake=100%\n",
      ">32 real=100% fake=100%\n",
      ">33 real=100% fake=100%\n",
      ">34 real=100% fake=100%\n",
      ">35 real=100% fake=100%\n",
      ">36 real=100% fake=100%\n",
      ">37 real=100% fake=100%\n",
      ">38 real=100% fake=100%\n",
      ">39 real=100% fake=100%\n",
      ">40 real=100% fake=100%\n",
      ">41 real=100% fake=100%\n",
      ">42 real=100% fake=100%\n",
      ">43 real=100% fake=100%\n",
      ">44 real=100% fake=100%\n",
      ">45 real=100% fake=100%\n",
      ">46 real=100% fake=100%\n",
      ">47 real=100% fake=100%\n",
      ">48 real=100% fake=100%\n",
      ">49 real=100% fake=100%\n",
      ">50 real=100% fake=100%\n",
      ">51 real=100% fake=100%\n",
      ">52 real=100% fake=100%\n",
      ">53 real=100% fake=100%\n",
      ">54 real=100% fake=100%\n",
      ">55 real=100% fake=100%\n",
      ">56 real=100% fake=100%\n",
      ">57 real=100% fake=100%\n",
      ">58 real=100% fake=100%\n",
      ">59 real=100% fake=100%\n",
      ">60 real=100% fake=100%\n",
      ">61 real=100% fake=100%\n",
      ">62 real=100% fake=100%\n",
      ">63 real=100% fake=100%\n",
      ">64 real=100% fake=100%\n",
      ">65 real=100% fake=100%\n",
      ">66 real=100% fake=100%\n",
      ">67 real=100% fake=100%\n",
      ">68 real=100% fake=100%\n",
      ">69 real=100% fake=100%\n",
      ">70 real=100% fake=100%\n",
      ">71 real=100% fake=100%\n",
      ">72 real=100% fake=100%\n",
      ">73 real=100% fake=100%\n",
      ">74 real=100% fake=100%\n",
      ">75 real=100% fake=100%\n",
      ">76 real=100% fake=100%\n",
      ">77 real=100% fake=100%\n",
      ">78 real=100% fake=100%\n",
      ">79 real=100% fake=100%\n",
      ">80 real=100% fake=100%\n",
      ">81 real=100% fake=100%\n",
      ">82 real=100% fake=100%\n",
      ">83 real=100% fake=100%\n",
      ">84 real=100% fake=100%\n",
      ">85 real=100% fake=100%\n",
      ">86 real=100% fake=100%\n",
      ">87 real=100% fake=100%\n",
      ">88 real=100% fake=100%\n",
      ">89 real=100% fake=100%\n",
      ">90 real=100% fake=100%\n",
      ">91 real=100% fake=100%\n",
      ">92 real=100% fake=100%\n",
      ">93 real=100% fake=100%\n",
      ">94 real=100% fake=100%\n",
      ">95 real=100% fake=100%\n",
      ">96 real=100% fake=100%\n",
      ">97 real=100% fake=100%\n",
      ">98 real=100% fake=100%\n",
      ">99 real=100% fake=100%\n",
      ">100 real=100% fake=100%\n"
     ]
    }
   ],
   "source": [
    "train_discriminator(model, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5327ff11",
   "metadata": {},
   "source": [
    "Generator Requirements: \n",
    "1. It must be able to generate an image as close as possible to the images in dataset and must be able to fool the discriminator\n",
    "2. The generator will consist of a deep neural network where the deep neural network is responsibe for the transformation of the prior distribution to the desired images distribution in the dataset.\n",
    "3. We will build a simple model which consists of both a convolutional type and dense layers\n",
    "4. A random prior sampler should also be created of random data sampling. Generally sampling is done from a guassian distribution in some random n dimensions and then converting the array to the desired size of the input\n",
    "5. The training of generator is done a bit differently unlike the initial training of the discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc01a3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random generator for 100*1 points in the latent space of 100 rv guassian\n",
    "def generate_latent_points(dimensions, n_samples):\n",
    "    # generate points in the dimensions\n",
    "    x_input = np.random.randn(dimensions * n_samples)\n",
    "    # reshape into a batch of inputs for the network\n",
    "    x_input = x_input.reshape(n_samples, dimensions)\n",
    "    return x_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70c41c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "generatormodel = Sequential([\n",
    "    # took 128*7*7 because it'll later be reshaped by the model to 7*7 images which later will be upscaled to 14*14 and then \n",
    "    # 28*28 later which in the end all the 128 images obtained via various filters will be merged into 1\n",
    "    # also we are trying to map the guassian vector of 100 dimension we sample 28*28 image via neural network\n",
    "    Dense(128*7*7, input_dim=100, activation = 'relu'),\n",
    "    Reshape((7, 7, 128)),\n",
    "    # upsample to 14x14\n",
    "    Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', activation = 'relu'),\n",
    "    # upsample to 28x28\n",
    "    Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', activation = 'relu'),\n",
    "    Conv2D(1, (7,7), activation='sigmoid', padding='same'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f190edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(generatormodel,show_shapes=True,show_layer_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "424c4f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 6272)              633472    \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 14, 14, 128)      262272    \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 28, 28, 128)      262272    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 28, 28, 1)         6273      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,164,289\n",
      "Trainable params: 1,164,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generatormodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d6858a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modifying the generate_fake_samples function so that the fake samples that will be generated will be coming from the \n",
    "# generator model\n",
    "def generate_fake_samples(g_model, n_samples):\n",
    "    x_input = generate_latent_points(100, n_samples)\n",
    "    # predict outputs\n",
    "    X = g_model.predict(x_input)\n",
    "    # create 'fake' class labels (0) because these are the fake images because these are being generated by the generator\n",
    "    y = np.zeros((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67112cd",
   "metadata": {},
   "source": [
    "# Training the generator model\n",
    "Training the generator model takes a bit of a thought because\n",
    "\n",
    "1. It must be trained based on the adversarial relationship between the generator and the discriminator model\n",
    "2. The weights in the generator model must be updated well when the discriminator is able to distinguish between the real and fake images well and the weight update should be less when the discriminator is not able to distinguish between the real and fake images well.\n",
    "\n",
    "Simplest approach is to create a new model which holds both the generator and discriminator model such that it takes input from the latent space of points and feeds it into generator, which then sends the input image into discriminator model and later capable of updating the weights of the generator The discriminator model\n",
    "\n",
    "1. The discriminator is concerned with distinguishing between real and fake examples, therefore the discriminator model can be trained in a standalone manner on examples of each\n",
    "2. Hence, the discriminators parameters will be marked as non-trainable\n",
    "\n",
    "Note: When the generator is trained as part of the GAN model, we are going to mark the generated samples as real because when the discriminator model classifies the generated images as fake, i.e, as 0, and when we mark as the images as real i.e, 1, the model will think of it as a large error and the parameters are updated well and when the discriminator classifies it as real, i.e, 1, the model won't see that as an error and the parameters won't be updated that well, as desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22bfff6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that clubs both generator model and the discriminator model along with making the discriminator model parameters as\n",
    "# non-trainable\n",
    "def define_gan(g_model, d_model):\n",
    "    # make weights in the discriminator not trainable\n",
    "    d_model.trainable = False\n",
    "    # connect them\n",
    "    model = Sequential()\n",
    "    # add generator\n",
    "    model.add(g_model)\n",
    "    # add the discriminator\n",
    "    model.add(d_model)\n",
    "    # compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26e931d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_model = define_gan(generatormodel, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de755c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_1 (Sequential)   (None, 28, 28, 1)         1164289   \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 1)                 40705     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,204,994\n",
      "Trainable params: 1,164,289\n",
      "Non-trainable params: 40,705\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "caeeb520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(gan_model,show_shapes=True,show_layer_names=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6c9d90",
   "metadata": {},
   "source": [
    "To train the model as a whole, we would train the GAN model along with training of the discriminator model because we had declared the discriminator model's parameters in the GAN model as non-trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec1c7b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=15, n_batch=256):\n",
    "    bat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "    half_batch = int(n_batch / 2)\n",
    "    for i in range(n_epochs):                                                  # manually enumerating epochs\n",
    "        print(\"Epoch \", i)                                          # just to measure the progress\n",
    "        for j in range(bat_per_epo):                                           # enumerating batches over the training set\n",
    "            print(\"Batch \", j)\n",
    "            X_real, y_real = generate_real_samples(dataset, half_batch)        # getting randomly selected 'real' samples\n",
    "            X_fake, y_fake = generate_fake_samples(g_model,  half_batch)  # generating 'fake' examples\n",
    "            X, y = np.vstack((X_real, X_fake)), np.vstack((y_real, y_fake))              # creating training set for the discriminator\n",
    "            d_loss, _ = d_model.train_on_batch(X, y)                           # updating discriminator model weights\n",
    "            X_gan = generate_latent_points(latent_dim, n_batch)  # preparing points in latent space as input for the generator\n",
    "            y_gan = np.ones((n_batch, 1))                          # creating inverted labels for the fake samples\n",
    "            g_loss = gan_model.train_on_batch(X_gan, y_gan)    # updating the generator via the discriminator's error   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c227c27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0\n",
      "Batch  0\n",
      "4/4 [==============================] - 1s 82ms/step\n",
      "Batch  1\n",
      "4/4 [==============================] - 0s 67ms/step\n",
      "Batch  2\n",
      "4/4 [==============================] - 0s 49ms/step\n",
      "Batch  3\n",
      "4/4 [==============================] - 0s 53ms/step\n",
      "Batch  4\n",
      "4/4 [==============================] - 0s 57ms/step\n",
      "Batch  5\n",
      "4/4 [==============================] - 0s 67ms/step\n",
      "Batch  6\n",
      "4/4 [==============================] - 0s 56ms/step\n",
      "Batch  7\n",
      "4/4 [==============================] - 0s 47ms/step\n",
      "Batch  8\n",
      "4/4 [==============================] - 0s 57ms/step\n",
      "Batch  9\n",
      "4/4 [==============================] - 0s 63ms/step\n",
      "Batch  10\n",
      "4/4 [==============================] - 0s 62ms/step\n",
      "Batch  11\n",
      "4/4 [==============================] - 0s 56ms/step\n",
      "Batch  12\n",
      "4/4 [==============================] - 0s 59ms/step\n",
      "Batch  13\n",
      "4/4 [==============================] - 0s 45ms/step\n",
      "Batch  14\n",
      "4/4 [==============================] - 0s 45ms/step\n",
      "Batch  15\n",
      "4/4 [==============================] - 0s 55ms/step\n",
      "Batch  16\n",
      "4/4 [==============================] - 0s 52ms/step\n",
      "Batch  17\n",
      "4/4 [==============================] - 0s 50ms/step\n",
      "Batch  18\n",
      "4/4 [==============================] - 0s 45ms/step\n",
      "Batch  19\n",
      "4/4 [==============================] - 0s 59ms/step\n",
      "Batch  20\n",
      "4/4 [==============================] - 0s 56ms/step\n",
      "Batch  21\n",
      "4/4 [==============================] - 0s 47ms/step\n",
      "Batch  22\n",
      "4/4 [==============================] - 0s 46ms/step\n",
      "Batch  23\n",
      "4/4 [==============================] - 0s 51ms/step\n",
      "Batch  24\n",
      "4/4 [==============================] - 0s 53ms/step\n",
      "Batch  25\n",
      "4/4 [==============================] - 0s 44ms/step\n",
      "Batch  26\n",
      "4/4 [==============================] - 0s 58ms/step\n",
      "Batch  27\n",
      "4/4 [==============================] - 0s 52ms/step\n",
      "Batch  28\n",
      "4/4 [==============================] - 0s 59ms/step\n",
      "Batch  29\n",
      "4/4 [==============================] - 0s 61ms/step\n",
      "Batch  30\n",
      "4/4 [==============================] - 0s 52ms/step\n",
      "Batch  31\n",
      "4/4 [==============================] - 0s 47ms/step\n",
      "Batch  32\n",
      "4/4 [==============================] - 0s 42ms/step\n",
      "Batch  33\n",
      "4/4 [==============================] - 0s 46ms/step\n",
      "Batch  34\n",
      "4/4 [==============================] - 0s 53ms/step\n",
      "Batch  35\n",
      "4/4 [==============================] - 0s 47ms/step\n",
      "Batch  36\n",
      "4/4 [==============================] - 0s 52ms/step\n",
      "Batch  37\n",
      "4/4 [==============================] - 0s 57ms/step\n",
      "Batch  38\n",
      "4/4 [==============================] - 0s 63ms/step\n",
      "Batch  39\n",
      "4/4 [==============================] - 0s 57ms/step\n",
      "Batch  40\n",
      "4/4 [==============================] - 0s 53ms/step\n",
      "Batch  41\n",
      "4/4 [==============================] - 0s 47ms/step\n",
      "Batch  42\n",
      "4/4 [==============================] - 0s 46ms/step\n",
      "Batch  43\n",
      "4/4 [==============================] - 0s 53ms/step\n",
      "Batch  44\n",
      "4/4 [==============================] - 0s 67ms/step\n",
      "Batch  45\n",
      "4/4 [==============================] - 0s 51ms/step\n",
      "Batch  46\n",
      "4/4 [==============================] - 0s 55ms/step\n",
      "Batch  47\n",
      "4/4 [==============================] - 0s 59ms/step\n",
      "Batch  48\n",
      "4/4 [==============================] - 0s 51ms/step\n",
      "Batch  49\n",
      "4/4 [==============================] - 0s 58ms/step\n",
      "Batch  50\n",
      "4/4 [==============================] - 0s 54ms/step\n",
      "Batch  51\n",
      "4/4 [==============================] - 0s 49ms/step\n",
      "Batch  52\n",
      "4/4 [==============================] - 0s 61ms/step\n",
      "Batch  53\n",
      "4/4 [==============================] - 0s 59ms/step\n",
      "Batch  54\n",
      "4/4 [==============================] - 0s 57ms/step\n",
      "Batch  55\n",
      "4/4 [==============================] - 0s 49ms/step\n",
      "Batch  56\n",
      "4/4 [==============================] - 0s 51ms/step\n",
      "Batch  57\n",
      "4/4 [==============================] - 0s 52ms/step\n",
      "Batch  58\n",
      "4/4 [==============================] - 0s 46ms/step\n",
      "Batch  59\n",
      "4/4 [==============================] - 0s 48ms/step\n",
      "Batch  60\n",
      "4/4 [==============================] - 0s 56ms/step\n",
      "Batch  61\n",
      "4/4 [==============================] - 0s 52ms/step\n",
      "Batch  62\n",
      "4/4 [==============================] - 0s 56ms/step\n",
      "Batch  63\n",
      "4/4 [==============================] - 0s 59ms/step\n",
      "Batch  64\n",
      "4/4 [==============================] - 0s 46ms/step\n",
      "Batch  65\n",
      "4/4 [==============================] - 0s 48ms/step\n",
      "Batch  66\n",
      "4/4 [==============================] - 0s 54ms/step\n",
      "Batch  67\n",
      "4/4 [==============================] - 0s 51ms/step\n",
      "Batch  68\n",
      "4/4 [==============================] - 0s 51ms/step\n",
      "Batch  69\n",
      "4/4 [==============================] - 0s 58ms/step\n",
      "Batch  70\n",
      "4/4 [==============================] - 0s 52ms/step\n",
      "Batch  71\n",
      "4/4 [==============================] - 0s 47ms/step\n",
      "Batch  72\n",
      "4/4 [==============================] - 0s 50ms/step\n",
      "Batch  73\n",
      "4/4 [==============================] - 0s 51ms/step\n",
      "Batch  74\n",
      "4/4 [==============================] - 0s 46ms/step\n",
      "Batch  75\n",
      "4/4 [==============================] - 0s 52ms/step\n",
      "Batch  76\n",
      "4/4 [==============================] - 0s 50ms/step\n",
      "Batch  77\n",
      "4/4 [==============================] - 0s 48ms/step\n",
      "Batch  78\n",
      "4/4 [==============================] - 0s 46ms/step\n",
      "Batch  79\n",
      "4/4 [==============================] - 0s 56ms/step\n",
      "Batch  80\n",
      "4/4 [==============================] - 0s 49ms/step\n",
      "Batch  81\n",
      "4/4 [==============================] - 0s 51ms/step\n",
      "Batch  82\n",
      "4/4 [==============================] - 0s 62ms/step\n",
      "Batch  83\n",
      "4/4 [==============================] - 0s 48ms/step\n",
      "Batch  84\n",
      "4/4 [==============================] - 0s 54ms/step\n",
      "Batch  85\n",
      "4/4 [==============================] - 0s 57ms/step\n",
      "Batch  86\n",
      "4/4 [==============================] - 0s 48ms/step\n",
      "Batch  87\n",
      "4/4 [==============================] - 0s 54ms/step\n",
      "Batch  88\n",
      "4/4 [==============================] - 0s 51ms/step\n",
      "Batch  89\n",
      "4/4 [==============================] - 0s 53ms/step\n",
      "Batch  90\n",
      "4/4 [==============================] - 0s 47ms/step\n",
      "Batch  91\n",
      "4/4 [==============================] - 0s 51ms/step\n",
      "Batch  92\n",
      "4/4 [==============================] - 0s 46ms/step\n",
      "Batch  93\n",
      "4/4 [==============================] - 0s 57ms/step\n",
      "Batch  94\n",
      "4/4 [==============================] - 0s 55ms/step\n",
      "Batch  95\n",
      "4/4 [==============================] - 0s 49ms/step\n",
      "Batch  96\n",
      "4/4 [==============================] - 0s 57ms/step\n",
      "Batch  97\n",
      "4/4 [==============================] - 0s 55ms/step\n",
      "Batch  98\n",
      "4/4 [==============================] - 0s 55ms/step\n",
      "Batch  99\n",
      "4/4 [==============================] - 0s 47ms/step\n",
      "Batch  100\n",
      "4/4 [==============================] - 0s 51ms/step\n",
      "Batch  101\n",
      "4/4 [==============================] - 0s 60ms/step\n",
      "Batch  102\n",
      "4/4 [==============================] - 0s 55ms/step\n",
      "Batch  103\n",
      "4/4 [==============================] - 0s 48ms/step\n",
      "Batch  104\n",
      "4/4 [==============================] - 0s 53ms/step\n",
      "Batch  105\n",
      "4/4 [==============================] - 0s 56ms/step\n",
      "Batch  106\n",
      "4/4 [==============================] - 0s 45ms/step\n",
      "Batch  107\n",
      "4/4 [==============================] - 0s 54ms/step\n",
      "Batch  108\n",
      "4/4 [==============================] - 0s 56ms/step\n",
      "Batch  109\n",
      "4/4 [==============================] - 0s 56ms/step\n",
      "Batch  110\n",
      "4/4 [==============================] - 0s 58ms/step\n",
      "Batch  111\n",
      "4/4 [==============================] - 0s 64ms/step\n",
      "Batch  112\n",
      "4/4 [==============================] - 0s 54ms/step\n",
      "Batch  113\n",
      "4/4 [==============================] - 0s 55ms/step\n",
      "Batch  114\n",
      "4/4 [==============================] - 0s 51ms/step\n",
      "Batch  115\n",
      "4/4 [==============================] - 0s 48ms/step\n",
      "Batch  116\n",
      "4/4 [==============================] - 0s 46ms/step\n",
      "Batch  117\n",
      "4/4 [==============================] - 0s 57ms/step\n",
      "Batch  118\n",
      "4/4 [==============================] - 0s 47ms/step\n",
      "Batch  119\n",
      "4/4 [==============================] - 0s 54ms/step\n",
      "Batch  120\n",
      "4/4 [==============================] - 0s 54ms/step\n"
     ]
    }
   ],
   "source": [
    "train(generatormodel, model, gan_model, X, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47447b6",
   "metadata": {},
   "source": [
    "## Evaluating the GAN model\n",
    "There's no proper way to evaluate the performance of the GAN model, its just going along the training time and visualising various images for clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f5fffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fakesamples = generate_fake_samples(generatormodel, n_samples)\n",
    "for i in range(n_samples):\n",
    "    pyplot.subplot(5, 5, 1 + i)\n",
    "    pyplot.axis('off')\n",
    "    pyplot.imshow(fakesamples[i, :, :, 0], cmap='gray_r')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c8b4e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
